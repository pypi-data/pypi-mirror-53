{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsHSQ1TEXDNZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from simulation_util import client_update\n",
    "import warnings\n",
    "\n",
    "# hide the warning message temporarily\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# auto-reload the modules everytime a cell is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfZrf09ZofuP"
   },
   "source": [
    "## Client Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "fZj9flYHXNd4",
    "outputId": "09beecb0-cd45-46d6-9932-77cef46d5044",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[28.48292577,  0.        ,  0.        ]]), array([-9.])]\n"
     ]
    }
   ],
   "source": [
    "# this data will be provided by the server\n",
    "features = [[1, 4, 3], [0, 2, 2], [1, 4, 0], [0, 5, 3], [1, 2, 1], [0, 2, 9]]\n",
    "labels = [1, 0, 1, 0, 1, 0]\n",
    "\n",
    "coefs = np.array([29., 0., 0.]) # should be of size num_classes * num_features\n",
    "intercepts = np.array([-9])\n",
    "weights = [coefs, intercepts]\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 3\n",
    "\n",
    "new_weights = client_update(weights, epochs, batch_size, features, labels)\n",
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Update Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights:  [[-1.88998529 -7.77928383  0.1247547 ]] [8.06948321]\n",
      "Updated Weights:  [[-3.14658285  2.60053666  5.43189638]] [8.60357767]\n",
      "Updated Weights:  [[-1.28140522  5.42823545  1.89898726]] [8.43339149]\n",
      "Updated Weights:  [[-3.74997627 10.91294467  1.0971158 ]] [5.33885579]\n",
      "Updated Weights:  [[4.42919342 6.61835419 8.26757996]] [9.09195967]\n",
      "Updated Weights:  [[-8.58616465  1.53515246 -1.22986693]] [6.34834551]\n",
      "Updated Weights:  [[ 6.09787979 -2.36450218 -2.20511742]] [16.86760162]\n",
      "Updated Weights:  [[-5.79978775 -4.49429409  1.88039804]] [7.42129726]\n",
      "Updated Weights:  [[7.07518744 6.76691657 3.90897526]] [9.50596262]\n",
      "Updated Weights:  [[-3.3246793   7.09700542  5.48971927]] [5.91119309]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from simulation_util import server_update\n",
    "\n",
    "init_weights = [np.array([0, 0, 0]), np.array([0])]\n",
    "client_fraction = 0.5\n",
    "num_rounds = 10\n",
    "epoch = 10\n",
    "batch_size = 25\n",
    "display_weight_per_round = True\n",
    "\n",
    "num_client = 100\n",
    "samples_per_client = 100\n",
    "num_features = 3\n",
    "features = np.random.randint(10, size=(num_client, samples_per_client, num_features))\n",
    "labels = np.random.randint(2, size=(num_client, samples_per_client))\n",
    "\n",
    "new_clf = server_update(init_weights, client_fraction, num_rounds, features, labels, epoch, batch_size, display_weight_per_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simulation Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 1, 'epoch': 1, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[  8.77069867,  -2.63840591,  31.31750977,  -9.57683456],\n",
      "       [ 22.80217526,  10.64899234,  16.78286   ,  -7.34525358],\n",
      "       [ -5.04143886,   7.95329319,  15.32743645, -16.63465208]]), array([-238.35135925, -256.52792777, -265.14371203])]\n",
      "Score: 0.343625\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 1, 'epoch': 5, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[ 10.47819007,  10.47905525,  26.27432185, -12.67122868],\n",
      "       [  5.68969177,  17.33458831,  13.31253131, -12.84603441],\n",
      "       [  5.86914394,  27.51810474,   2.03090646,  -4.10592691]]), array([-287.22822838, -274.64129043, -268.71344802])]\n",
      "Score: 0.323625\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 0.1, 'epoch': 1, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[  2.81441517,   1.59151156,  30.54974067, -21.23439465],\n",
      "       [ 11.66534148,  14.6668196 ,  22.20708959, -10.49478632],\n",
      "       [ -3.70501003,  18.63368381,  19.3027747 , -12.44612883]]), array([-260.06837414, -263.27617307, -260.52720789])]\n",
      "Score: 0.341875\n",
      "\n",
      "\n",
      "Training...\n",
      "Params:  {'batch_size': 40, 'client_fraction': 0.1, 'epoch': 5, 'init_weight': [array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([0., 0., 0.])], 'num_rounds': 10}\n",
      "Weights: [array([[10.90720941,  7.56617518, 37.03893698, -4.63416877],\n",
      "       [14.86724896, 28.93517126,  9.92362945, -2.82764793],\n",
      "       [-1.6532394 , 31.44136606, 20.05719171,  0.26481936]]), array([-272.19289296, -280.67637824, -271.45168284])]\n",
      "Score: 0.342500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from simulation_util import server_update\n",
    "import numpy as np\n",
    "import random_data_gen as rdata_gen\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "NUM_SAMPLES = 20000\n",
    "NUM_LABELS = 3\n",
    "NUM_FEATURES = 4\n",
    "NUM_CLIENTS = 100\n",
    "g_prms = rdata_gen.InputGenParams(NUM_SAMPLES, NUM_LABELS, NUM_FEATURES, NUM_CLIENTS)\n",
    "df = pd.read_csv(\"datasets/blob_S20000_L3_F4_U100.csv\")\n",
    "\n",
    "sim_labels, sim_features = rdata_gen.transform_data_for_simulator_format(df, g_prms)\n",
    "features = np.array(sim_features)\n",
    "labels = np.array(sim_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=0)\n",
    "\n",
    "init_weights = np.zeros((NUM_LABELS, NUM_FEATURES), dtype=np.float64, order=\"C\")\n",
    "init_intercept = np.zeros(NUM_LABELS, dtype=np.float64, order=\"C\")\n",
    "\n",
    "# Find all the permutations of the parameters\n",
    "param_grid = {\"client_fraction\": [1, 0.1],\n",
    "              \"epoch\": [1, 5],\n",
    "              \"batch_size\": [40], # TODO: need to implement an infinite batch size\n",
    "              \"init_weight\": [[init_weights, init_intercept]],\n",
    "              \"num_rounds\": [10]}\n",
    "\n",
    "# run training/testing over all parameter combinations to get the best combination\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"Training...\")\n",
    "    print(\"Params: \", params)\n",
    "    classifier = server_update(params[\"init_weight\"], params[\"client_fraction\"], params[\"num_rounds\"], X_train, y_train, params[\"epoch\"], params[\"batch_size\"], False)\n",
    "    weights = [classifier.coef_, classifier.intercept_]\n",
    "\n",
    "    # need to remove the client dimension from our data for testing \n",
    "    # ex: [[[1, 1], [2, 2]], [[3, 3], [4, 4]]] needs to become [[1, 1], [2, 2], [3, 3], [4, 4]] for features \n",
    "    # and [[1, 2], [3, 4]] needs to become [1, 2, 3, 4] for labels \n",
    "    reshaped_X_test = np.reshape(X_test, (X_test.shape[0] * X_test.shape[1], X_test.shape[2]))\n",
    "    reshaped_y_test = np.reshape(y_test, y_test.size)\n",
    "    \n",
    "    score = classifier.score(reshaped_X_test, reshaped_y_test)\n",
    "\n",
    "    print('Weights: {}\\nScore: {:f}\\n\\n'.format(weights, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Federated Learning Simulation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
