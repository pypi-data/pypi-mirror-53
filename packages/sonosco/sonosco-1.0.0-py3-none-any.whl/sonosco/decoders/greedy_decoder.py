#!/usr/bin/env python
# ----------------------------------------------------------------------------
# Copyright 2015-2016 Nervana Systems Inc.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ----------------------------------------------------------------------------
# Modified to support pytorch Tensors

import torch
from sonosco.serialization import serializable

from .decoder import Decoder


# TODO: Make it actually serializable by extracting init
@serializable
class GreedyDecoder(Decoder):
    def __init__(self, labels="_'ABCDEFGHIJKLMNOPQRSTUVWXYZ#", blank_index=None):
        super(GreedyDecoder, self).__init__(labels, blank_index)

    def convert_to_strings(self, sequences: list,
                           sizes: dict = None,
                           remove_repetitions: bool = False,
                           return_offsets: bool = False) -> any:
        """
        Given a list of numeric sequences, returns the corresponding strings
        Args:
            sequences: sequences to process
            sizes: sizes of sequences
            remove_repetitions: indicator
            return_offsets: indicator

        Returns:

        """
        strings = []
        offsets = [] if return_offsets else None
        for x in range(len(sequences)):
            seq_len = sizes[x] if sizes is not None else len(sequences[x])
            string, string_offsets = self.process_string(sequences[x], seq_len, remove_repetitions)
            strings.append([string])  # We only return one path
            if return_offsets:
                offsets.append([string_offsets])
        if return_offsets:
            return strings, offsets
        else:
            return strings

    def process_string(self, sequence: dict, size: int, remove_repetitions: bool = False) -> (str, torch.Tensor):
        """
        Process string to tensor
        Args:
            sequence: sequence to process
            size: size of sequences
            remove_repetitions: indicator

        Returns: string, tensor

        """
        string = ''
        offsets = []
        for i in range(size):
            idx = sequence[i].item()
            if idx in self.int_to_char:
                char = self.int_to_char[idx]
                if self.blank_index is None or char != self.int_to_char.get(self.blank_index):
                    # if this char is a repetition and remove_repetitions=true, then skip
                    if remove_repetitions and i != 0 and char == self.int_to_char.get(sequence[i - 1].item()):
                        pass
                    # elif char == self.labels[self.space_index]:
                    #    string += ' '
                    #    offsets.append(i)
                    else:
                        string = string + char
                        offsets.append(i)
        return string, torch.tensor(offsets, dtype=torch.int)

    def decode(self, probs: torch.Tensor, sizes: dict = None, remove_repetitions: bool = False):
        """
        Returns the argmax decoding given the probability matrix. Removes
        repeated elements in the sequence, as well as blanks.

        Arguments:
            probs: Tensor of character probabilities from the network. Expected shape of batch x seq_length x output_dim
            sizes(optional): Size of each sequence in the mini-batch
            remove_repetitions(optional)
        Returns:
            strings: sequences of the model's best guess for the transcription on inputs
            offsets: time step per character predicted
        """
        _, max_probs = torch.max(probs, 2)
        strings, offsets = self.convert_to_strings(max_probs.view(max_probs.size(0), max_probs.size(1)), sizes,
                                                   remove_repetitions=remove_repetitions, return_offsets=True)
        return strings, offsets
